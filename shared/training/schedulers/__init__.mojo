"""
Learning Rate Schedulers

Scheduler implementations for adjusting learning rates during training.

Includes:
- StepLR (Step decay scheduler)
- CosineAnnealingLR (Cosine annealing scheduler)
- ExponentialLR (Exponential decay scheduler)
- WarmupLR (Warmup scheduler)

All schedulers implement the LRScheduler trait for consistent interface.
"""

# Export scheduler implementations
# These will be populated during implementation phase

# from .base import LRScheduler
# from .step_decay import StepLR
# from .cosine import CosineAnnealingLR
# from .exponential import ExponentialLR
# from .warmup import WarmupLR

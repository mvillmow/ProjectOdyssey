{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Operations in ML Odyssey\n",
    "\n",
    "Learn the fundamentals of ExTensor - ML Odyssey's N-dimensional tensor type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExTensor Basics\n",
    "\n",
    "ExTensor is ML Odyssey's core tensor type, similar to PyTorch's Tensor or TensorFlow's Tensor.\n",
    "\n",
    "Key features:\n",
    "- **Multi-dimensional**: Support for 1D, 2D, 3D, 4D+ tensors\n",
    "- **Type-safe**: Compile-time checking of dimensions and dtypes\n",
    "- **Zero-copy operations**: Reshape, slice, and transpose without copying\n",
    "- **SIMD-optimized**: Automatic vectorization for performance\n",
    "- **Multiple dtypes**: float32, float16, bfloat16, float8, int8, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Type Support\n",
    "\n",
    "ExTensor supports multiple data types optimized for different use cases:\n",
    "\n",
    "| DType | Size | Precision | Use Case |\n",
    "|-------|------|-----------|----------|\n",
    "| float32 (FP32) | 4 bytes | Full | Training, reference |\n",
    "| float16 (FP16) | 2 bytes | Half | Mixed precision training |\n",
    "| bfloat16 (BF16) | 2 bytes | Half | TPU/hardware optimized |\n",
    "| float8 (FP8) | 1 byte | Extremely low | Inference only |\n",
    "| int8 | 1 byte | Integer | Quantized models |\n",
    "\n",
    "**Note**: Dtype selection significantly impacts:\n",
    "- Memory usage (lower = faster, less storage)\n",
    "- Precision (higher = more accurate, slower)\n",
    "- Speed (hardware support varies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors\n",
    "\n",
    "### From Mojo Code\n",
    "\n",
    "In Mojo, you'd create tensors like:\n",
    "\n",
    "```mojo\n",
    "from shared.core.extensor import ExTensor\n",
    "from shared.data.types import DType\n",
    "\n",
    "# Create tensor with shape (3, 4, 5)\n",
    "var t = ExTensor[DType.float32]((3, 4, 5))\n",
    "\n",
    "# Initialize with zeros\n",
    "t.fill(0.0)\n",
    "\n",
    "# Or random values\n",
    "t.random_normal(0.0, 1.0)  # mean=0, std=1\n",
    "```\n",
    "\n",
    "### From Python Notebooks\n",
    "\n",
    "In notebooks, we create NumPy arrays that mimic ExTensor behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from notebooks.utils import visualization\n",
    "\n",
    "# Create tensors with NumPy\n",
    "# (These can be saved and loaded by Mojo)\n",
    "\n",
    "# 2D tensor (matrix) of shape (3, 4)\n",
    "tensor_2d = np.random.randn(3, 4).astype(np.float32)\n",
    "print(f\"2D Tensor shape: {tensor_2d.shape}\")\n",
    "print(f\"2D Tensor dtype: {tensor_2d.dtype}\")\n",
    "print(tensor_2d)\n",
    "\n",
    "# 3D tensor of shape (2, 3, 4)\n",
    "tensor_3d = np.random.randn(2, 3, 4).astype(np.float32)\n",
    "print(f\"\\n3D Tensor shape: {tensor_3d.shape}\")\n",
    "\n",
    "# 4D tensor (typical for CNN: batch_size, channels, height, width)\n",
    "tensor_4d = np.random.randn(4, 3, 28, 28).astype(np.float32)\n",
    "print(f\"4D Tensor shape: {tensor_4d.shape}\")\n",
    "print(f\"Total elements: {np.prod(tensor_4d.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations\n",
    "\n",
    "### Shape Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape - change tensor shape without copying data\n",
    "t = np.arange(12).reshape(3, 4).astype(np.float32)\n",
    "print(\"Original shape:\", t.shape)\n",
    "t_reshaped = t.reshape(2, 6)\n",
    "print(\"Reshaped to (2, 6):\")\n",
    "print(t_reshaped)\n",
    "\n",
    "# Transpose - swap dimensions\n",
    "t_transposed = t.T\n",
    "print(\"\\nTransposed shape:\", t_transposed.shape)\n",
    "print(t_transposed)\n",
    "\n",
    "# Squeeze - remove dimensions of size 1\n",
    "t_with_extra = t.reshape(1, 3, 4, 1)\n",
    "print(\"\\nShape with extra dims:\", t_with_extra.shape)\n",
    "t_squeezed = np.squeeze(t_with_extra)\n",
    "print(\"Squeezed shape:\", t_squeezed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = np.array([[5.0, 6.0], [7.0, 8.0]])\n",
    "\n",
    "# Element-wise operations\n",
    "print(\"a + b:\")\n",
    "print(a + b)\n",
    "\n",
    "print(\"\\na * b (element-wise):\")\n",
    "print(a * b)\n",
    "\n",
    "print(\"\\nsqrt(a):\")\n",
    "print(np.sqrt(a))\n",
    "\n",
    "print(\"\\nexp(a):\")\n",
    "print(np.exp(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication (dot product)\n",
    "a = np.array([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = np.array([[5.0, 6.0], [7.0, 8.0]])\n",
    "\n",
    "print(\"Matrix multiplication (a @ b):\")\n",
    "print(a @ b)\n",
    "\n",
    "# Batched matrix multiplication (common in deep learning)\n",
    "batch_a = np.random.randn(32, 10, 20)  # 32 matrices of shape (10, 20)\n",
    "batch_b = np.random.randn(32, 20, 15)  # 32 matrices of shape (20, 15)\n",
    "batch_result = np.matmul(batch_a, batch_b)\n",
    "print(f\"\\nBatched matmul result shape: {batch_result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "Broadcasting allows operations on tensors of different shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting example\n",
    "a = np.array([[1.0, 2.0, 3.0]])  # shape (1, 3)\n",
    "b = np.array([[1.0], [2.0], [3.0]])  # shape (3, 1)\n",
    "\n",
    "print(f\"a shape: {a.shape}\")\n",
    "print(f\"b shape: {b.shape}\")\n",
    "print(\"\\na + b (broadcasts to (3, 3)):\")\n",
    "print(a + b)\n",
    "\n",
    "# Normalizing batches\n",
    "batch = np.random.randn(32, 10)  # 32 samples of 10 features\n",
    "mean = np.mean(batch, axis=0, keepdims=True)  # shape (1, 10)\n",
    "std = np.std(batch, axis=0, keepdims=True)  # shape (1, 10)\n",
    "normalized = (batch - mean) / (std + 1e-8)  # broadcasts to (32, 10)\n",
    "print(f\"\\nNormalized batch shape: {normalized.shape}\")\n",
    "print(f\"Mean after normalization: {normalized.mean():.6f}\")\n",
    "print(f\"Std after normalization: {normalized.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Let's visualize a tensor as a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample tensor\n",
    "t = np.random.randn(10, 10)\n",
    "\n",
    "# Visualize it\n",
    "fig = visualization.visualize_tensor(t, title=\"Random 10x10 Tensor\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize a structured tensor\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = np.linspace(-5, 5, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.sin(np.sqrt(X**2 + Y**2))\n",
    "\n",
    "fig = visualization.visualize_tensor(Z, title=\"Sinc Function Pattern\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Tensors are multi-dimensional arrays** - can be 1D (vectors), 2D (matrices), 3D+ (higher-order)\n",
    "2. **Dtypes matter** - choose precision based on your needs (speed vs accuracy)\n",
    "3. **Zero-copy operations** - reshape/transpose don't copy data, just change the view\n",
    "4. **Broadcasting** - enables efficient operations on different shapes\n",
    "5. **SIMD optimization** - Mojo automatically vectorizes operations for speed\n",
    "\n",
    "Next: Learn how to build neural networks using these tensors!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

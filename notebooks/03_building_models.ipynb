{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Networks with ML Odyssey\n",
    "\n",
    "Learn how to construct neural network architectures using ExTensor layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Layers\n",
    "\n",
    "ML Odyssey provides optimized implementations of common layer types:\n",
    "\n",
    "### Convolutional Layers\n",
    "- **Conv2D**: 2D convolution for image processing\n",
    "- **DepthwiseConv2D**: Depthwise separable convolutions (efficient)\n",
    "- **TransposeConv2D**: Learnable upsampling via convolution\n",
    "\n",
    "### Fully Connected\n",
    "- **Linear**: Dense matrix multiplication layer\n",
    "- **Embedding**: Look-up table for categorical inputs\n",
    "\n",
    "### Normalization\n",
    "- **BatchNorm**: Batch normalization for training stability\n",
    "- **LayerNorm**: Layer normalization for attention models\n",
    "\n",
    "### Pooling\n",
    "- **MaxPool2D**: Maximum pooling for dimensionality reduction\n",
    "- **AvgPool2D**: Average pooling\n",
    "- **AdaptiveAvgPool2D**: Output-size-aware pooling\n",
    "\n",
    "### Activation\n",
    "- **ReLU**: Rectified Linear Unit (most common)\n",
    "- **LeakyReLU**: ReLU with non-zero negative slope\n",
    "- **Sigmoid**: S-shaped activation (0 to 1)\n",
    "- **Tanh**: Hyperbolic tangent (-1 to 1)\n",
    "- **GELU**: Gaussian Error Linear Unit (modern)\n",
    "- **SiLU/Swish**: Smooth activation\n",
    "\n",
    "### Regularization\n",
    "- **Dropout**: Random neuron deactivation (training only)\n",
    "- **Residual**: Skip connections (ResNet-style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Configuration\n",
    "\n",
    "Each layer requires specific parameters:\n",
    "\n",
    "### Conv2D Example\n",
    "\n",
    "```mojo\n",
    "var conv = Conv2D(\n",
    "    in_channels=3,      # Input: RGB image\n",
    "    out_channels=32,    # Output: 32 filters\n",
    "    kernel_size=3,      # 3x3 filter\n",
    "    stride=1,           # Move filter by 1 pixel\n",
    "    padding=1,          # Add 1 pixel padding\n",
    "    dtype=DType.float32\n",
    ")\n",
    "```\n",
    "\n",
    "### Linear Example\n",
    "\n",
    "```mojo\n",
    "var linear = Linear(\n",
    "    in_features=784,    # Flattened 28x28 image\n",
    "    out_features=128,   # Hidden units\n",
    "    dtype=DType.float32\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic Architectures\n",
    "\n",
    "### LeNet-5 (1998)\n",
    "\n",
    "First successful deep CNN, revolutionized handwritten digit recognition:\n",
    "\n",
    "```\n",
    "Input (28x28)\n",
    "  ↓\n",
    "Conv2D(1, 6, 5) → ReLU → MaxPool(2)  # 28→24→12\n",
    "  ↓\n",
    "Conv2D(6, 16, 5) → ReLU → MaxPool(2) # 12→8→4\n",
    "  ↓\n",
    "Flatten → Linear(16*4*4, 120) → ReLU\n",
    "  ↓\n",
    "Linear(120, 84) → ReLU\n",
    "  ↓\n",
    "Linear(84, 10)  # Output probabilities\n",
    "```\n",
    "\n",
    "### AlexNet (2012)\n",
    "\n",
    "Deep network that won ImageNet, popularized GPU training:\n",
    "\n",
    "```\n",
    "Input (224x224x3)\n",
    "  ↓\n",
    "Conv2D(3, 96, 11, stride=4) → ReLU → MaxPool(3)\n",
    "  ↓\n",
    "Conv2D(96, 256, 5) → ReLU → MaxPool(3)\n",
    "  ↓\n",
    "Conv2D(256, 384, 3) → ReLU\n",
    "Conv2D(384, 384, 3) → ReLU\n",
    "Conv2D(384, 256, 3) → ReLU → MaxPool(3)\n",
    "  ↓\n",
    "Dropout(0.5)\n",
    "Linear(256*6*6, 4096) → ReLU → Dropout(0.5)\n",
    "Linear(4096, 4096) → ReLU → Dropout(0.5)\n",
    "Linear(4096, 1000)  # 1000 ImageNet classes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition in Mojo\n",
    "\n",
    "```mojo\n",
    "struct LeNet5:\n",
    "    var conv1: Conv2D\n",
    "    var pool1: MaxPool2D\n",
    "    var conv2: Conv2D\n",
    "    var pool2: MaxPool2D\n",
    "    var fc1: Linear\n",
    "    var fc2: Linear\n",
    "    var fc3: Linear\n",
    "\n",
    "    fn __init__(out self):\n",
    "        self.conv1 = Conv2D(1, 6, kernel_size=5)\n",
    "        self.pool1 = MaxPool2D(2)\n",
    "        self.conv2 = Conv2D(6, 16, kernel_size=5)\n",
    "        self.pool2 = MaxPool2D(2)\n",
    "        self.fc1 = Linear(16*4*4, 120)\n",
    "        self.fc2 = Linear(120, 84)\n",
    "        self.fc3 = Linear(84, 10)\n",
    "\n",
    "    fn forward(self, x: ExTensor) -> ExTensor:\n",
    "        var x = self.conv1(x)\n",
    "        x = x.relu()\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = x.relu()\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.flatten()\n",
    "        x = self.fc1(x).relu()\n",
    "        x = self.fc2(x).relu()\n",
    "        x = self.fc3(x)  # No activation on output\n",
    "        \n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization\n",
    "\n",
    "Proper weight initialization is crucial for training stability:\n",
    "\n",
    "### Xavier/Glorot Initialization\n",
    "```mojo\n",
    "# For layers with tanh/sigmoid\n",
    "limit = sqrt(6.0 / (fan_in + fan_out))\n",
    "weight = uniform_random(-limit, limit)\n",
    "```\n",
    "\n",
    "### Kaiming/He Initialization\n",
    "```mojo\n",
    "# For layers with ReLU\n",
    "std = sqrt(2.0 / fan_in)\n",
    "weight = normal_random(0, std)\n",
    "```\n",
    "\n",
    "### Bias Initialization\n",
    "```mojo\n",
    "# Almost always zero\n",
    "bias = zeros(out_features)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Model Parameters\n",
    "\n",
    "In Python notebooks, we can count and inspect parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from notebooks.utils import visualization\n",
    "\n",
    "# Simulate model parameters\n",
    "layers = [\n",
    "    {\"name\": \"conv1\", \"type\": \"Conv2D(1, 6, 5)\", \"output_shape\": \"(N, 6, 24, 24)\", \"params\": 1*6*5*5 + 6},\n",
    "    {\"name\": \"relu1\", \"type\": \"ReLU\", \"output_shape\": \"(N, 6, 24, 24)\", \"params\": 0},\n",
    "    {\"name\": \"pool1\", \"type\": \"MaxPool2D(2)\", \"output_shape\": \"(N, 6, 12, 12)\", \"params\": 0},\n",
    "    {\"name\": \"conv2\", \"type\": \"Conv2D(6, 16, 5)\", \"output_shape\": \"(N, 16, 8, 8)\", \"params\": 6*16*5*5 + 16},\n",
    "    {\"name\": \"relu2\", \"type\": \"ReLU\", \"output_shape\": \"(N, 16, 8, 8)\", \"params\": 0},\n",
    "    {\"name\": \"pool2\", \"type\": \"MaxPool2D(2)\", \"output_shape\": \"(N, 16, 4, 4)\", \"params\": 0},\n",
    "    {\"name\": \"fc1\", \"type\": \"Linear(256, 120)\", \"output_shape\": \"(N, 120)\", \"params\": 256*120 + 120},\n",
    "    {\"name\": \"fc2\", \"type\": \"Linear(120, 84)\", \"output_shape\": \"(N, 84)\", \"params\": 120*84 + 84},\n",
    "    {\"name\": \"fc3\", \"type\": \"Linear(84, 10)\", \"output_shape\": \"(N, 10)\", \"params\": 84*10 + 10},\n",
    "]\n",
    "\n",
    "visualization.display_model_summary(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Design Principles\n",
    "\n",
    "1. **Deeper is not always better** - But deeper networks can learn more complex patterns\n",
    "2. **Bottleneck design** - Reduce spatial dimensions, increase feature channels\n",
    "3. **Skip connections** - Allow gradient flow in very deep networks\n",
    "4. **Batch normalization** - Stabilizes training of deep networks\n",
    "5. **Regularization** - Dropout, weight decay prevent overfitting\n",
    "\n",
    "Next: Train your first model!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

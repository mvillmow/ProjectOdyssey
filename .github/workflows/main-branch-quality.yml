name: Main Branch Quality

# Extended quality checks for main branch only
# These complement the existing comprehensive-tests.yml with additional analysis
# Runs on: pushes to main, manual dispatch

on:
  # Run only on pushes to main
  push:
    branches:
      - main

  # Manual trigger for ad-hoc runs
  workflow_dispatch:
    inputs:
      run_extended:
        description: 'Run extended analysis (SIMD, complexity)'
        required: false
        default: 'true'
        type: boolean

permissions:
  contents: read
  pull-requests: write

jobs:
  # ============================================================================
  # Mojo Compilation Check - Verify ALL .mojo files compile
  # ============================================================================
  mojo-compilation:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    name: "Mojo Compilation"

    steps:
      - name: Checkout code
        uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3

      - name: Set up Pixi
        uses: prefix-dev/setup-pixi@v0.9.3
        with:
          pixi-version: latest
          cache: true

      - name: Cache Pixi environments
        uses: actions/cache@v4
        with:
          path: ~/.pixi
          key: pixi-${{ runner.os }}-${{ hashFiles('pixi.toml') }}
          restore-keys: |
            pixi-${{ runner.os }}-

      - name: Check Mojo version
        run: pixi run mojo --version

      - name: Compile all Mojo files
        run: |
          echo "=================================================="
          echo "Compiling ALL Mojo files in repository"
          echo "=================================================="

          REPO_ROOT="$(pwd)"
          mkdir -p compilation-results

          total=0
          passed=0
          failed=0
          failed_files=""
          warnings_files=""

          # Find all .mojo files (excluding test files for now - they're handled separately)
          for mojo_file in $(find shared -name "*.mojo" -type f | sort); do
            total=$((total + 1))
            echo ""
            echo "Compiling: $mojo_file"

            # Try to compile the file (not run, just parse and type-check)
            output=$(pixi run mojo -I "$REPO_ROOT" "$mojo_file" 2>&1) || true

            if echo "$output" | grep -q "error:"; then
              echo "‚ùå FAILED: $mojo_file"
              failed=$((failed + 1))
              failed_files="$failed_files\n  - $mojo_file"
              echo "$output" | head -20
            elif echo "$output" | grep -q "warning:"; then
              echo "‚ö†Ô∏è  WARNINGS: $mojo_file"
              passed=$((passed + 1))
              warnings_files="$warnings_files\n  - $mojo_file"
            else
              echo "‚úÖ PASSED: $mojo_file"
              passed=$((passed + 1))
            fi
          done

          echo ""
          echo "=================================================="
          echo "Mojo Compilation Summary"
          echo "=================================================="
          echo "Total files: $total"
          echo "Passed: $passed"
          echo "Failed: $failed"

          # Save results
          cat > compilation-results/summary.txt << EOF
          Mojo Compilation Check
          ======================
          Total files: $total
          Passed: $passed
          Failed: $failed
          EOF

          if [ -n "$failed_files" ]; then
            echo -e "\nFailed files:$failed_files" >> compilation-results/summary.txt
          fi

          if [ -n "$warnings_files" ]; then
            echo -e "\nFiles with warnings:$warnings_files" >> compilation-results/summary.txt
          fi

          cat compilation-results/summary.txt

          if [ $failed -gt 0 ]; then
            echo ""
            echo "‚ùå FAIL: $failed Mojo files failed to compile"
            exit 1
          fi

      - name: Upload compilation results
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: mojo-compilation-results
          path: compilation-results/
          retention-days: 7

  # ============================================================================
  # Test Execution with Coverage Tracking
  # ============================================================================
  test-with-metrics:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    name: "Tests with Metrics"

    steps:
      - name: Checkout code
        uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3

      - name: Set up Pixi
        uses: prefix-dev/setup-pixi@v0.9.3
        with:
          pixi-version: latest
          cache: true

      - name: Run all tests and collect metrics
        run: |
          echo "=================================================="
          echo "Running ALL tests with metrics collection"
          echo "=================================================="

          REPO_ROOT="$(pwd)"
          mkdir -p test-metrics

          # Metrics tracking
          total_tests=0
          passed_tests=0
          failed_tests=0
          skipped_tests=0
          test_duration_total=0

          # Results by category
          declare -A category_results

          # Find and run all test files
          for test_file in $(find tests -name "test_*.mojo" -type f | sort); do
            category=$(dirname "$test_file" | sed 's|tests/||')

            echo ""
            echo "=================================================="
            echo "Running: $test_file"
            echo "Category: $category"
            echo "=================================================="

            start_time=$(date +%s)
            total_tests=$((total_tests + 1))

            if output=$(pixi run mojo -I "$REPO_ROOT" -I . "$test_file" 2>&1); then
              echo "‚úÖ PASSED"
              passed_tests=$((passed_tests + 1))
              status="PASS"

              # Check for skipped tests in output
              if echo "$output" | grep -qi "skipped\|disabled"; then
                skipped_tests=$((skipped_tests + 1))
              fi
            else
              echo "‚ùå FAILED"
              echo "$output" | tail -30
              failed_tests=$((failed_tests + 1))
              status="FAIL"
            fi

            end_time=$(date +%s)
            duration=$((end_time - start_time))
            test_duration_total=$((test_duration_total + duration))

            # Track by category
            if [ -z "${category_results[$category]}" ]; then
              category_results[$category]="0:0"
            fi
            IFS=':' read -r cat_pass cat_fail <<< "${category_results[$category]}"
            if [ "$status" = "PASS" ]; then
              cat_pass=$((cat_pass + 1))
            else
              cat_fail=$((cat_fail + 1))
            fi
            category_results[$category]="$cat_pass:$cat_fail"
          done

          echo ""
          echo "=================================================="
          echo "Test Metrics Summary"
          echo "=================================================="
          echo "Total tests: $total_tests"
          echo "Passed: $passed_tests"
          echo "Failed: $failed_tests"
          echo "Skipped: $skipped_tests"
          echo "Total duration: ${test_duration_total}s"

          # Generate metrics file
          cat > test-metrics/summary.json << EOF
          {
            "timestamp": "$(date -Iseconds)",
            "total_tests": $total_tests,
            "passed": $passed_tests,
            "failed": $failed_tests,
            "skipped": $skipped_tests,
            "duration_seconds": $test_duration_total,
            "pass_rate": $(echo "scale=2; $passed_tests * 100 / $total_tests" | bc 2>/dev/null || echo "0")
          }
          EOF

          # Generate markdown report
          cat > test-metrics/report.md << EOF
          # Test Metrics Report

          **Run Date**: $(date -Iseconds)
          **Commit**: ${{ github.sha }}

          ## Summary

          | Metric | Value |
          |--------|-------|
          | Total Tests | $total_tests |
          | Passed | $passed_tests |
          | Failed | $failed_tests |
          | Skipped | $skipped_tests |
          | Duration | ${test_duration_total}s |
          | Pass Rate | $(echo "scale=1; $passed_tests * 100 / $total_tests" | bc 2>/dev/null || echo "0")% |

          ## Results by Category

          | Category | Passed | Failed |
          |----------|--------|--------|
          EOF

          for category in "${!category_results[@]}"; do
            IFS=':' read -r cat_pass cat_fail <<< "${category_results[$category]}"
            echo "| $category | $cat_pass | $cat_fail |" >> test-metrics/report.md
          done

          cat test-metrics/report.md

          if [ $failed_tests -gt 0 ]; then
            exit 1
          fi

      - name: Upload test metrics
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: test-metrics
          path: test-metrics/
          retention-days: 30

  # ============================================================================
  # Code Quality Analysis (Extended - runs on schedule or manual trigger)
  # ============================================================================
  code-quality:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    name: "Code Quality Analysis"
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'push'

    steps:
      - name: Checkout code
        uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install analysis tools
        run: |
          pip install radon lizard

      - name: Analyze Python code complexity
        run: |
          echo "=================================================="
          echo "Python Code Complexity Analysis"
          echo "=================================================="

          mkdir -p quality-reports

          # Cyclomatic complexity
          echo "## Cyclomatic Complexity (Python)" > quality-reports/complexity.md
          echo "" >> quality-reports/complexity.md
          echo "Functions with complexity > 10 (consider refactoring):" >> quality-reports/complexity.md
          echo '```' >> quality-reports/complexity.md
          radon cc scripts/ -a -nc 2>/dev/null || echo "No complex functions found"
          echo '```' >> quality-reports/complexity.md

          # Maintainability index
          echo "" >> quality-reports/complexity.md
          echo "## Maintainability Index" >> quality-reports/complexity.md
          echo '```' >> quality-reports/complexity.md
          radon mi scripts/ -s 2>/dev/null || echo "No files analyzed"
          echo '```' >> quality-reports/complexity.md

          cat quality-reports/complexity.md

      - name: Analyze Mojo code metrics
        run: |
          echo "=================================================="
          echo "Mojo Code Metrics"
          echo "=================================================="

          # Count lines of code
          echo "" >> quality-reports/complexity.md
          echo "## Mojo Code Statistics" >> quality-reports/complexity.md
          echo "" >> quality-reports/complexity.md

          total_mojo_files=$(find shared tests -name "*.mojo" | wc -l)
          total_mojo_lines=$(find shared tests -name "*.mojo" -exec cat {} \; 2>/dev/null | wc -l)
          total_functions=$(grep -r "^fn " shared tests --include="*.mojo" 2>/dev/null | wc -l)
          total_structs=$(grep -r "^struct " shared tests --include="*.mojo" 2>/dev/null | wc -l)
          total_traits=$(grep -r "^trait " shared tests --include="*.mojo" 2>/dev/null | wc -l)

          cat >> quality-reports/complexity.md << EOF
          | Metric | Count |
          |--------|-------|
          | Mojo Files | $total_mojo_files |
          | Lines of Code | $total_mojo_lines |
          | Functions (fn) | $total_functions |
          | Structs | $total_structs |
          | Traits | $total_traits |
          EOF

          # Find large files (potential candidates for splitting)
          echo "" >> quality-reports/complexity.md
          echo "### Large Mojo Files (>500 lines)" >> quality-reports/complexity.md
          echo "" >> quality-reports/complexity.md
          find shared tests -name "*.mojo" -exec wc -l {} \; 2>/dev/null | \
            awk '$1 > 500 {print "- " $2 ": " $1 " lines"}' | \
            sort -t: -k2 -nr >> quality-reports/complexity.md || echo "None found"

          cat quality-reports/complexity.md

      - name: Check for TODO/FIXME comments
        run: |
          echo "" >> quality-reports/complexity.md
          echo "## Technical Debt Markers" >> quality-reports/complexity.md
          echo "" >> quality-reports/complexity.md

          todo_count=$(grep -r "TODO" shared tests scripts --include="*.mojo" --include="*.py" 2>/dev/null | wc -l)
          fixme_count=$(grep -r "FIXME" shared tests scripts --include="*.mojo" --include="*.py" 2>/dev/null | wc -l)
          hack_count=$(grep -r "HACK" shared tests scripts --include="*.mojo" --include="*.py" 2>/dev/null | wc -l)

          cat >> quality-reports/complexity.md << EOF
          | Marker | Count |
          |--------|-------|
          | TODO | $todo_count |
          | FIXME | $fixme_count |
          | HACK | $hack_count |
          EOF

      - name: Upload quality reports
        uses: actions/upload-artifact@v5
        with:
          name: code-quality-reports
          path: quality-reports/
          retention-days: 30

  # ============================================================================
  # SIMD Optimization Analysis (Extended)
  # ============================================================================
  simd-analysis:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    name: "SIMD Analysis"
    if: github.event_name == 'workflow_dispatch' && inputs.run_extended == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3

      - name: Analyze SIMD usage opportunities
        run: |
          echo "=================================================="
          echo "SIMD Usage Analysis"
          echo "=================================================="

          mkdir -p simd-reports

          # Count SIMD usage
          simd_count=$(grep -r "SIMD\[" shared --include="*.mojo" 2>/dev/null | wc -l)
          vectorize_count=$(grep -r "vectorize" shared --include="*.mojo" 2>/dev/null | wc -l)
          parallelize_count=$(grep -r "parallelize" shared --include="*.mojo" 2>/dev/null | wc -l)

          cat > simd-reports/analysis.md << EOF
          # SIMD Optimization Analysis

          ## Current Usage

          | Pattern | Count |
          |---------|-------|
          | SIMD[] declarations | $simd_count |
          | vectorize() calls | $vectorize_count |
          | parallelize() calls | $parallelize_count |

          ## Potential Optimization Opportunities

          Files with tensor operations that might benefit from SIMD:
          EOF

          # Find files with loop-heavy operations
          echo "" >> simd-reports/analysis.md
          echo '```' >> simd-reports/analysis.md
          grep -rl "for .* in range" shared --include="*.mojo" 2>/dev/null | \
            xargs -I{} sh -c 'echo "{}": $(grep -c "for .* in range" "{}")' 2>/dev/null | \
            sort -t: -k2 -nr | head -10 >> simd-reports/analysis.md || echo "None found"
          echo '```' >> simd-reports/analysis.md

          cat simd-reports/analysis.md

      - name: Upload SIMD analysis
        uses: actions/upload-artifact@v5
        with:
          name: simd-analysis
          path: simd-reports/
          retention-days: 30

  # ============================================================================
  # Combined Quality Report
  # ============================================================================
  quality-report:
    needs: [mojo-compilation, test-with-metrics, code-quality]
    runs-on: ubuntu-latest
    if: always()
    name: "Quality Report"

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v6
        with:
          path: all-reports/
          pattern: "*"
          merge-multiple: false

      - name: Generate combined quality report
        run: |
          echo "# üìä Main Branch Quality Report" > quality-report.md
          echo "" >> quality-report.md
          echo "**Commit**: \`${{ github.sha }}\`" >> quality-report.md
          echo "**Run**: [\`${{ github.run_number }}\`](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> quality-report.md
          echo "**Date**: $(date -Iseconds)" >> quality-report.md
          echo "" >> quality-report.md

          # Compilation status
          echo "## üîß Compilation" >> quality-report.md
          if [ -f "all-reports/mojo-compilation-results/summary.txt" ]; then
            echo '```' >> quality-report.md
            cat "all-reports/mojo-compilation-results/summary.txt" >> quality-report.md
            echo '```' >> quality-report.md
          else
            echo "‚ö†Ô∏è Compilation results not available" >> quality-report.md
          fi
          echo "" >> quality-report.md

          # Test metrics
          echo "## üß™ Test Results" >> quality-report.md
          if [ -f "all-reports/test-metrics/report.md" ]; then
            cat "all-reports/test-metrics/report.md" >> quality-report.md
          else
            echo "‚ö†Ô∏è Test metrics not available" >> quality-report.md
          fi
          echo "" >> quality-report.md

          # Code quality
          echo "## üìà Code Quality" >> quality-report.md
          if [ -f "all-reports/code-quality-reports/complexity.md" ]; then
            cat "all-reports/code-quality-reports/complexity.md" >> quality-report.md
          else
            echo "‚ö†Ô∏è Code quality report not available" >> quality-report.md
          fi
          echo "" >> quality-report.md

          cat quality-report.md

      - name: Upload combined report
        uses: actions/upload-artifact@v5
        with:
          name: main-branch-quality-report
          path: quality-report.md
          retention-days: 90

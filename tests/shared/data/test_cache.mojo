"""Tests for CachedDataset wrapper.

Tests that CachedDataset correctly caches samples and respects limits.
"""

from tests.shared.conftest import (
    assert_true,
    assert_equal,
    assert_almost_equal,
)
from shared.data import ExTensorDataset, CachedDataset
from shared.core.extensor import ExTensor, ones, zeros
from collections import List


# ============================================================================
# CachedDataset Creation Tests
# ============================================================================


fn test_cached_dataset_creation() raises:
    """Test creating CachedDataset.

    CachedDataset should wrap a base dataset.
    """
    var data_shape: List[Int] = [10, 3, 32, 32]
    var label_shape: List[Int] = [10, 10]

    var data = ones(data_shape, DType.float32)
    var labels = zeros(label_shape, DType.float32)

    var base_dataset = ExTensorDataset(data^, labels^)
    var cached = CachedDataset(base_dataset^, max_cache_size=-1)

    assert_equal(cached.__len__(), 10)
    assert_true(cached.cache_enabled)


fn test_cached_dataset_length() raises:
    """Test that CachedDataset.__len__ matches base dataset.

    The length should reflect the number of samples.
    """
    var data_shape: List[Int] = [42, 3, 32, 32]
    var label_shape: List[Int] = [42, 10]

    var data = ones(data_shape, DType.float32)
    var labels = zeros(label_shape, DType.float32)

    var base_dataset = ExTensorDataset(data^, labels^)
    var cached = CachedDataset(base_dataset^, max_cache_size=-1)

    assert_equal(cached.__len__(), 42)


fn test_cached_dataset_stores_samples() raises:
    """Test that CachedDataset stores samples in cache.

    Accessing a sample should add it to the cache.
    """
    var data_shape: List[Int] = [5, 1, 8, 8]
    var label_shape: List[Int] = [5, 10]

    var data = ones(data_shape, DType.float32)
    var labels = zeros(label_shape, DType.float32)

    var base_dataset = ExTensorDataset(data^, labels^)
    var cached = CachedDataset(base_dataset^, max_cache_size=-1)

    # Access a sample
    var sample_data, sample_labels = cached[0]

    # Check that it's in cache
    assert_equal(cached.cache.__len__(), 1)


fn test_cached_dataset_cache_hit() raises:
    """Test that cache hits are tracked.

    Multiple accesses to same sample should count as cache hits.
    """
    var data_shape: List[Int] = [5, 1, 8, 8]
    var label_shape: List[Int] = [5, 10]

    var data = ones(data_shape, DType.float32)
    var labels = zeros(label_shape, DType.float32)

    var base_dataset = ExTensorDataset(data^, labels^)
    var cached = CachedDataset(base_dataset^, max_cache_size=-1)

    # First access - cache miss
    var _ = cached[0]
    assert_equal(cached.cache_hits, 0)
    assert_equal(cached.cache_misses, 1)

    # Second access - cache hit
    var _ = cached[0]
    assert_equal(cached.cache_hits, 1)
    assert_equal(cached.cache_misses, 1)


fn test_cached_dataset_max_cache_size() raises:
    """Test that max_cache_size limits number of cached samples.

    When cache size reaches limit, new samples shouldn't be added.
    """
    var data_shape: List[Int] = [10, 1, 8, 8]
    var label_shape: List[Int] = [10, 10]

    var data = ones(data_shape, DType.float32)
    var labels = zeros(label_shape, DType.float32)

    var base_dataset = ExTensorDataset(data^, labels^)
    var cached = CachedDataset(base_dataset^, max_cache_size=3)

    # Access 5 samples
    for i in range(5):
        var _ = cached[i]

    # Cache size should be limited to 3
    assert_equal(cached.cache.__len__(), 3)


fn test_cached_dataset_disabled_cache() raises:
    """Test that caching can be disabled.

    When cache_enabled=False, nothing should be cached.
    """
    var data_shape: List[Int] = [5, 1, 8, 8]
    var label_shape: List[Int] = [5, 10]

    var data = ones(data_shape, DType.float32)
    var labels = zeros(label_shape, DType.float32)

    var base_dataset = ExTensorDataset(data^, labels^)
    var cached = CachedDataset(base_dataset^, max_cache_size=-1, cache_enabled=False)

    var _ = cached[0]

    # Cache should be empty
    assert_true(cached.cache.__len__() == 0)


fn test_cached_dataset_preload_cache() raises:
    """Test preloading entire cache.

    _preload_cache should populate cache with all samples.
    """
    var data_shape: List[Int] = [5, 1, 8, 8]
    var label_shape: List[Int] = [5, 10]

    var data = ones(data_shape, DType.float32)
    var labels = zeros(label_shape, DType.float32)

    var base_dataset = ExTensorDataset(data^, labels^)
    var cached = CachedDataset(base_dataset^, max_cache_size=-1)

    cached._preload_cache()

    # Cache should have all 5 samples
    assert_equal(cached.cache.__len__(), 5)


fn test_cached_dataset_clear_cache() raises:
    """Test clearing the cache.

    clear_cache should remove all cached samples.
    """
    var data_shape: List[Int] = [5, 1, 8, 8]
    var label_shape: List[Int] = [5, 10]

    var data = ones(data_shape, DType.float32)
    var labels = zeros(label_shape, DType.float32)

    var base_dataset = ExTensorDataset(data^, labels^)
    var cached = CachedDataset(base_dataset^, max_cache_size=-1)

    # Add to cache
    var _ = cached[0]
    assert_equal(cached.cache.__len__(), 1)

    # Clear
    cached.clear_cache()
    assert_equal(cached.cache.__len__(), 0)


fn test_cached_dataset_enable_disable() raises:
    """Test enabling and disabling cache.

    Should be able to toggle caching on/off.
    """
    var data_shape: List[Int] = [5, 1, 8, 8]
    var label_shape: List[Int] = [5, 10]

    var data = ones(data_shape, DType.float32)
    var labels = zeros(label_shape, DType.float32)

    var base_dataset = ExTensorDataset(data^, labels^)
    var cached = CachedDataset(base_dataset^, max_cache_size=-1)

    # Cache is enabled by default
    assert_true(cached.cache_enabled)

    # Disable
    cached.disable_cache()
    assert_true(not cached.cache_enabled)

    # Enable again
    cached.enable_cache()
    assert_true(cached.cache_enabled)


fn test_cached_dataset_hit_rate() raises:
    """Test cache hit rate calculation.

    Hit rate should be hits / (hits + misses).
    """
    var data_shape: List[Int] = [5, 1, 8, 8]
    var label_shape: List[Int] = [5, 10]

    var data = ones(data_shape, DType.float32)
    var labels = zeros(label_shape, DType.float32)

    var base_dataset = ExTensorDataset(data^, labels^)
    var cached = CachedDataset(base_dataset^, max_cache_size=-1)

    # No accesses yet - should return 0.0
    assert_equal(cached.get_hit_rate(), Float32(0.0))

    # 2 accesses to same sample - 1 hit, 1 miss
    var _ = cached[0]
    var _ = cached[0]

    var hit_rate = cached.get_hit_rate()
    assert_almost_equal(hit_rate, Float32(0.5), Float32(0.01))


fn test_cached_dataset_get_stats() raises:
    """Test cache statistics.

    get_cache_stats should return (cache_size, hits, misses).
    """
    var data_shape: List[Int] = [5, 1, 8, 8]
    var label_shape: List[Int] = [5, 10]

    var data = ones(data_shape, DType.float32)
    var labels = zeros(label_shape, DType.float32)

    var base_dataset = ExTensorDataset(data^, labels^)
    var cached = CachedDataset(base_dataset^, max_cache_size=-1)

    var _ = cached[0]
    var _ = cached[0]

    var cache_size, hits, misses = cached.get_cache_stats()

    assert_equal(cache_size, 1)
    assert_equal(hits, 1)
    assert_equal(misses, 1)


fn main() raises:
    """Run all tests."""
    print("Testing CachedDataset...")
    test_cached_dataset_creation()
    test_cached_dataset_length()
    test_cached_dataset_stores_samples()
    test_cached_dataset_cache_hit()
    test_cached_dataset_max_cache_size()
    test_cached_dataset_disabled_cache()
    test_cached_dataset_preload_cache()
    test_cached_dataset_clear_cache()
    test_cached_dataset_enable_disable()
    test_cached_dataset_hit_rate()
    test_cached_dataset_get_stats()
    print("All CachedDataset tests passed!")

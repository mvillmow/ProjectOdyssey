# Day Nine: Breaking Free From Process Overhead

**Project:** ML Odyssey Manual
**Date:** November 15, 2025
**Branch:** `main`
**Tags:** #workflow-optimization #process-design #bulk-handling #claude-code-web #skills

---

## TL;DR

Hit a wall with the 5-phase process (plan → test → implementation → package → cleanup)—it's perfect for feature development but overkill for minor changes like adding CI/CD phases, refactoring, or updating documentation. Decided to bulk-handle low-scrutiny issues instead of the full review cycle for everything. Discovered Claude Code on the web has major blockers (no GitHub CLI access) that prevent real agentic workflows. Started delegating async work to web Claude Code with the $1,000 credit while using skills-based approaches to extend my local Claude Code Pro limits.

---

## Getting Tired of the Speed

I'm noticing that I am getting tired of the speed at which things are moving. It isn't that the speed is too slow, just that the process I have come up with is too clunky for many things.

The 5-step process of `plan → test → implementation → package → cleanup` works brilliantly for feature development. But it doesn't really work for other types of development, like:

- Adding a new CI/CD phase
- Refactoring code
- Adding skills/agents
- Improving documentation

For these tasks, the full ceremony feels excessive. So I decided to just skip a lot of steps and bulk handle a bunch of things.

---

## Bulk Handling of Issues

There are issues that don't need the same level of scrutiny as core algorithms or high-level plans. I've created a flow that is fairly thorough, but I'm running into issues where the process of:

1. Create
1. Test
1. Review
1. Handle the review
1. Re-review
1. Approve

...is time-consuming for minor issues.

### The Scrutiny Question

It is true that LLMs sometimes get things wrong, but is it really that important to make sure they do or not?

**I posit that it's not that important for 95-99% of all code created.** This level of scrutiny does not matter for most work.

I've designed this setup to be "good enough" for most code, and then I'll have to make a judgement call on what needs higher levels of scrutiny.

### The Agent Idea

I'm hoping I can get an agent to do this judgement call and have it flag code as requiring human review. On second thought, that IS a good idea for an agent, so I'll create it.

This would be a review-triage agent that categorizes changes by risk level and routes accordingly.

---

## Claude Code Web Issues

Claude Code on the web is actually a huge impediment for development.

The free $1,000 of compute is useful, but really, it is only good for creating simple things. The problem is that **I am blocked from using GitHub CLI**, which makes manipulation of the repository in an automatic fashion quite problematic.

This is a blocker for any real development, as having scripts:

- Pull code
- Post reviews
- Open issues
- Merge PRs
- Handle automated workflows

...is actually very important for many of my agentic flows.

### The Workaround

I'll hack around it, but until this gets fixed, I don't think I'll use Claude Code for the web for production workflows.

The web version is useful for async, isolated tasks that don't need repository automation. But for the core agentic orchestration? It's a non-starter.

---

## Skills

One thing I did find helpful for Claude Code on the web is **asynchronously doing tasks that were not being worked on**—so just another Claude Code account.

I had it refactor my agents to give them access to Claude Code skills and also handle a lot of tasks without using my limited Claude Code Pro credits.

### The Week-Over-Week Plan

Once I hit the limit for Claude Code for the week, I'll go ahead and do a full analysis of:

- **Week 1**: Initial agents
- **Week 2**: Model-optimized agents
- **Week 3**: Agents with skills

Week 3 analysis will then happen after I hit the limit there, and it will be skills-based, so the amount of code I can produce on a weekly basis should go up each time before I hit the usage limits.

I'm hoping with a skills-based approach, it will allow me to code all week before I hit my weekly limit.

### The Iterative Optimization

Then for Week 4, I'll optimize the skills and agents and once again see how it compares over time.

This is starting to get interesting. Let's analyze it tomorrow.

---

## Three Discoveries

### Discovery 1: Not All Code Needs the Same Scrutiny

The 5-phase process is designed for high-risk, complex work. But 95-99% of code doesn't need that level of scrutiny.

The solution is tiered review processes based on risk:

- **Low risk** (docs, minor refactors): Bulk handling, minimal review
- **Medium risk** (new features, non-critical algorithms): Standard review
- **High risk** (core algorithms, security-critical): Full 5-phase process

This dramatically reduces overhead without sacrificing quality where it matters.

### Discovery 2: GitHub CLI Blocking Is a Real Impediment

Claude Code on the web's lack of GitHub CLI access isn't just an inconvenience—it's a fundamental blocker for agentic workflows.

Without programmatic repository access, agents can't:

- Automatically create PRs
- Post review comments
- Update issues
- Trigger workflows

This forces manual intervention, defeating the purpose of agent orchestration. Until this is fixed, web Claude Code is limited to isolated, non-repository tasks.

### Discovery 3: Asynchronous Task Delegation Is Effective

Using web Claude Code credits for async work (agent refactoring, documentation) while reserving local Pro credits for core development is a viable strategy.

This workload distribution:

- Maximizes credit utilization
- Prevents bottlenecks
- Allows parallel progress on multiple fronts

The key is clear task separation: web handles isolated refactoring, local handles repository orchestration.

---

## What's Next

Immediate priorities:

1. **Create review-triage agent** - Automatically categorize changes by risk level and route to appropriate review process
1. **Analyze Week 2 metrics** - Compare model-optimized agents against Week 1 baseline
1. **Begin Week 3 with skills** - Test whether skills-based approach extends weekly code output before hitting limits
1. **Refine bulk handling workflows** - Formalize which change types qualify for expedited review
1. **Document GitHub CLI workarounds** - Create fallback strategies for web Claude Code limitations

---

## Reflections

This day taught me something important about process design:

1. **Process should match risk** - Using the same heavyweight process for all changes is wasteful. Risk-based tiering is essential.
1. **Tool limitations shape workflows** - GitHub CLI blocking in web Claude Code isn't just an annoyance—it fundamentally changes what's possible with agents.
1. **Credit optimization is a real consideration** - With finite API budgets, workload distribution between local and web becomes a strategic decision.
1. **Speed requires flexibility** - The original 5-phase process was correct for high-risk work, but flexibility to bypass it for low-risk work unlocks real velocity.

The infrastructure is solid. The agents work. Now it's about tuning the workflows to match the actual risk profile of the work, not treating everything as equally critical.

---

**Status:** Process optimization in progress, skills-based approach beginning, Week 3 experiments starting

**Next:** Create review-triage agent, analyze Week 2 metrics, begin skills-based workflows

### Stats

- 5-phase process: Perfect for features, overkill for 95% of other work
- 1 review-triage agent concept created
- 2 Claude Code accounts: local (orchestration) + web (async tasks)
- $1,000 web credits available for isolated work
- 1 developer learning that not all process is good process

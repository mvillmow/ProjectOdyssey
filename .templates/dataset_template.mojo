# {{snake_name}}.mojo
"""
{{name}} dataset loader.

Auto-generated by scripts/generators/generate_dataset.py
"""

from shared.datasets import Dataset
from shared.core import ExTensor


struct {{name}}(Dataset):
    """{{name}} dataset.

    A custom dataset loader.
    """

    var data: List[ExTensor]
    var targets: List[ExTensor]
    var data_dir: String

    fn __init__(out self, data_dir: String, train: Bool = True):
        """Initialize dataset.

        Args:
            data_dir: Path to dataset directory
            train: Whether to load training or test split
        """
        self.data_dir = data_dir
        self.data = List[ExTensor]()
        self.targets = List[ExTensor]()

        var split = "train" if train else "test"
        self._load_data(split)

    fn _load_data(mut self, split: String):
        """Load data from source.

        Args:
            split: Data split to load ("train" or "test")
        """
        # TODO: Implement data loading
        raise Error("Not implemented: _load_data")

    fn __len__(self) -> Int:
        """Get dataset size.

        Returns:
            Number of samples
        """
        return len(self.data)

    fn __getitem__(self, idx: Int) -> Tuple[ExTensor, ExTensor]:
        """Get item by index.

        Args:
            idx: Sample index

        Returns:
            (data, target) tuple
        """
        return (self.data[idx], self.targets[idx])

    fn get_batch(self, indices: List[Int]) -> Tuple[ExTensor, ExTensor]:
        """Get a batch of samples.

        Args:
            indices: List of sample indices

        Returns:
            (data_batch, targets_batch) tuple
        """
        var batch_data = List[ExTensor]()
        var batch_targets = List[ExTensor]()

        for idx in indices:
            var sample = self[idx[]]
            batch_data.append(sample[0])
            batch_targets.append(sample[1])

        # TODO: Stack into batch tensors
        return (batch_data[0], batch_targets[0])
